import streamlit as st
import requests


#è®¾è®¡ç•Œé¢
backend_url="http://127.0.0.1:6166/chat"
st.set_page_config(page_title="èŠå¤©æœºå™¨äºº",page_icon="ğŸ¤–")
#è®¾è®¡èŠå¤©å¯¹è¯æ¡†
st.title("ğŸ¤–TT")
def clear_chat_history():
    st.session_state.history=[]
with st.sidebar:
    st.title("ChatBot")
    sys_prompt=st.text_input("ç³»ç»Ÿæç¤ºè¯:",value="You are a helpful assistant.")
    history_len=st.slider("ä¿ç•™å†å²è®°å½•å¯¹è¯çš„æ•°é‡:",min_value=1,max_value=10,value=1,step=1)
    temperature=st.slider("temperature:",min_value=0.01,max_value=2.0,value=0.5,step=0.01)
    top_p=st.slider("top_p:",min_value=0.01,max_value=1.0,value=0.5,step=0.01)
    max_tokens=st.slider("max_tokens:",min_value=256,max_value=4096,value=1024,step=8)
    stream=st.checkbox("stream",value=True)
    st.button("æ¸…é™¤èŠå¤©å†å²è®°å½•",on_click=clear_chat_history())

if "history" not in st.session_state:
    st.session_state.history=[]
#æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

#æ˜¾ç¤ºè¾“å…¥æ¡†å’Œå‘é€æŒ‰é’®
#:=æµ·è±¡è¿ç®—ç¬¦ï¼Œç”¨äºæ£€æŸ¥èµ‹å€¼çš„å†…å®¹æ˜¯å¦ä¸ºç©º
if prompt:=st.chat_input("æ¥èŠå¤©"):
    #æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    #æ„å»ºè¯·æ±‚æ•°æ®
    data={
        "query":prompt,
        "sys_prompt":sys_prompt,
        "history_len":history_len,
        "temperature":temperature,
        "top_p":top_p,
        "max_tokens":max_tokens,
        "stream":stream

    }
    #å‘é€è¯·æ±‚åˆ°åç«¯
    response=requests.post(backend_url,json=data,stream=True)
    if response.status_code==200:
        assistant_placeholder=st.chat_message("assistant")
        assistant_text=assistant_placeholder.markdown("")
        chunks=""
        if stream:
            for chunk in response.iter_content(chunk_size=None,decode_unicode=True):
                #å¤„ç†ç›¸åº”çš„å†…å®¹ï¼Œå¹¶ç´¯åŠ 
                chunks +=chunk
                #å®æ—¶æ˜¾ç¤ºå’Œæ›´æ–°æ¶ˆæ¯
                assistant_text.markdown(chunks)
        else:
            for chunk in response.iter_content(chunk_size=None,decode_unicode=True):
                chunks +=chunk
            assistant_text.markdown(chunks)
    st.session_state.history.append({"role":"user","content":prompt})
    st.session_state.history.append({"role":"assistant", "content": chunks})